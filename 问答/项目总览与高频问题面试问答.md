# 项目总览与高频问题面试问答

> 本文档是智能座舱汽车知识问答系统的总览，包含项目介绍、技术选型、难点亮点等高频面试问题。

---

## 一、项目介绍（1-2分钟版本）

### Q1：请介绍一下你的这个项目

**30秒版：**
> 我做的是一个智能座舱汽车知识问答系统，基于RAG架构。用户提问后，系统先从知识库召回相关文档，再用大模型生成答案。我负责了整个Pipeline的搭建和优化，包括Embedding微调、Rerank微调、vLLM部署，最终在2000条测试集上达到88.6%的准确率。

**1分钟版（加细节）：**
> 这是一个面向车主的智能问答系统，用户可以用自然语言询问智能座舱的各种功能，比如"怎么用语音控制空调"。
>
> 技术架构是经典的RAG：
> - **召回层**：用M3E做向量检索 + BM25做关键词检索，双路召回
> - **重排层**：用BGE-reranker对召回结果精排
> - **生成层**：用Qwen-7B-Chat通过vLLM部署，生成最终答案
>
> 我的主要工作：
> 1. 对M3E进行领域微调，Recall@10提升3%
> 2. 对BGE-reranker微调，Precision提升2%
> 3. 用vLLM在4×V100上部署，支持512并发，首Token延迟2秒
>
> 最终效果：2000条测试样本，准确率88.6%。

---

## 二、技术选型问答

### Q2：为什么选择M3E而不是BGE或其他Embedding模型？

| 模型 | 维度 | 中文效果 | 选择理由 |
|------|------|----------|----------|
| M3E-large | 1024 | ⭐⭐⭐⭐ | 中文优化好，开源可微调 |
| BGE-large | 1024 | ⭐⭐⭐⭐ | 效果相当，但M3E在我们数据上略好 |
| text2vec | 768 | ⭐⭐⭐ | 维度小，效果稍差 |
| OpenAI Ada | 1536 | ⭐⭐⭐⭐⭐ | 效果最好但成本高、不可微调 |

**实际对比：** 在我们400条验证集上，M3E的Recall@10比BGE高1.2%，所以选了M3E。

---

### Q3：为什么用FAISS而不是Milvus/Pinecone？

**考虑因素：**
- 数据规模：~10K chunks，属于小规模
- 部署环境：单机4×V100
- 团队熟悉度：FAISS更轻量

**选择FAISS的原因：**
1. **够用**：万级数据，Flat索引毫秒级响应
2. **简单**：纯Python调用，不需要额外运维
3. **成熟**：Facebook出品，稳定可靠

**什么时候该用Milvus：**
- 数据量>100万
- 需要分布式部署
- 需要实时增删改

---

### Q4：为什么选Qwen-7B而不是其他模型？

| 模型 | 参数量 | 中文效果 | 显存占用 | 选择理由 |
|------|--------|----------|----------|----------|
| Qwen-7B-Chat | 7B | ⭐⭐⭐⭐⭐ | ~14GB | 中文最强7B，阿里持续维护 |
| ChatGLM2-6B | 6B | ⭐⭐⭐⭐ | ~13GB | 效果略逊于Qwen |
| Llama2-7B | 7B | ⭐⭐⭐ | ~14GB | 中文需要额外训练 |
| Baichuan-7B | 7B | ⭐⭐⭐⭐ | ~14GB | 效果接近，但社区不如Qwen活跃 |

**选择Qwen的原因：**
1. 中文理解和生成能力最强
2. 对话能力好，适合问答场景
3. vLLM官方支持好
4. 阿里持续迭代，文档完善

---

### Q5：为什么用vLLM而不是直接用Transformers推理？

**性能对比（同等硬件）：**
| 方案 | 吞吐量 | 首Token延迟 | 并发支持 |
|------|--------|-------------|----------|
| Transformers | 500 token/s | 5s | 1-2 |
| vLLM | 12K token/s | 2s | 512 |

**vLLM的核心优势：**
1. **PagedAttention**：显存利用率从30%提升到90%+
2. **Continuous Batching**：动态批处理，高并发
3. **生产就绪**：OpenAI兼容API，易于集成

---

## 三、项目难点与解决方案

### Q6：这个项目你遇到的最大挑战是什么？

**挑战：召回效果差，大量相关但不正确的文档被召回**

**具体现象：**
- 用户问"语音控制空调怎么用"
- 召回了"语音控制导航"、"空调保养方法"等相关但不正确的内容
- 导致最终答案跑题

**解决过程：**

1. **问题定位**
   - 分析Bad Case，发现是语义相似但意图不同的问题
   - 基础M3E无法区分这种细粒度差异

2. **方案一：Hard Negative Mining + Embedding微调**
   - 构造4200条三元组数据
   - 用当前模型召回的"难负样本"训练
   - Recall@10提升3%

3. **方案二：引入Rerank**
   - 召回Top20，Rerank精排到Top3
   - 用Cross-encoder捕捉Query-Doc的交互关系
   - Precision提升2%

4. **方案三：BM25兜底**
   - 有些关键词明确的问题，向量检索反而不如关键词
   - 双路召回互补

**最终效果：** 端到端准确率从82%提升到88.6%

---

### Q7：如果再给你时间，你会怎么进一步优化？

**短期优化：**
1. **Query改写**：用户问题可能不规范，先用LLM改写再检索
2. **多轮对话**：当前是单轮，可以加上下文记忆
3. **答案后处理**：格式化、去重复、加引用来源

**长期优化：**
1. **知识图谱增强**：对实体关系建图，支持推理类问题
2. **主动学习**：收集用户反馈，持续优化
3. **多模态**：支持图片问答（如"这个按钮是什么功能"）

---

## 四、数据流与系统架构

### Q8：请画一下你系统的整体架构

```
用户问题
    │
    ▼
┌─────────────────────────────────────┐
│           Query Processing          │
│  (分词、纠错、Query改写 - 可选)       │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│            双路召回                  │
│  ┌─────────────┐  ┌─────────────┐   │
│  │   M3E+FAISS │  │    BM25     │   │
│  │  (向量检索)  │  │ (关键词检索) │   │
│  └─────────────┘  └─────────────┘   │
│         │                │          │
│         └────────┬───────┘          │
│                  ▼                  │
│            合并去重 Top20            │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│         BGE-Reranker                │
│      精排 → Top3                    │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│         Qwen-7B (vLLM)              │
│   Prompt = 问题 + 召回文档 → 答案    │
└─────────────────────────────────────┘
    │
    ▼
  返回答案
```

---

### Q9：你们的Prompt是怎么设计的？

```python
system_prompt = """你是一个智能座舱助手，请根据以下参考资料回答用户问题。
要求：
1. 只根据参考资料回答，不要编造信息
2. 如果资料中没有相关内容，请说"抱歉，我没有找到相关信息"
3. 回答要简洁准确，使用用户能理解的语言
"""

user_prompt = """
参考资料：
{retrieved_documents}

用户问题：{question}

请回答：
"""
```

**Prompt设计要点：**
1. **角色设定**：明确是"智能座舱助手"
2. **约束幻觉**："只根据参考资料回答"
3. **兜底机制**："没有找到相关信息"
4. **格式要求**："简洁准确"

---

## 五、指标与效果

### Q10：你项目的核心指标有哪些？各是多少？

| 阶段 | 指标 | 数值 | 说明 |
|------|------|------|------|
| Embedding | Recall@10 | 88% | 微调后+3% |
| Rerank | Precision@3 | 提升2% | 微调后 |
| 端到端 | 准确率 | 88.6% | 2000条测试集 |
| 推理 | 首Token延迟 | 2s | vLLM部署 |
| 推理 | 吞吐量 | 12K token/s | 4×V100 |
| 推理 | 并发 | 512 | Benchmark压测 |

---

### Q11：88.6%的准确率是怎么算的？

```python
def calculate_accuracy(test_data, model):
    correct = 0
    for question, golden_answer in test_data:
        # 1. 走完整RAG流程
        retrieved = retrieve(question)
        reranked = rerank(question, retrieved)
        generated = llm_generate(question, reranked)
        
        # 2. 人工判断是否正确
        # 标准：答案能正确回答问题，关键信息无误
        is_correct = human_evaluate(generated, golden_answer)
        
        if is_correct:
            correct += 1
    
    return correct / len(test_data)  # 1772/2000 = 88.6%
```

---

## 六、常见追问

### Q12：你在这个项目中具体负责什么？

> 这是我**独立完成**的学习实践项目，完整走了一遍RAG系统的搭建流程：
> 1. **数据准备**：构造测试集，用GPT-4扩写到2000条
> 2. **召回模块**：M3E微调、FAISS索引、BM25、双路融合
> 3. **重排模块**：BGE-reranker微调
> 4. **推理部署**：vLLM在GPU服务器上的部署和调优
> 5. **效果评测**：设计评估指标，完成离线评测

---

### Q13：项目上线了吗？

> 这个项目是我的**学习实践项目**，没有正式上线到生产环境。
> 
> 但是我做了完整的**离线评测**：
> - 2000条测试样本，准确率88.6%
> - Benchmark压测：512并发下稳定运行，首Token延迟2s
> 
> **如果要上线，还需要：**
> - 接入监控系统（Prometheus + Grafana）
> - 加上限流、降级、熔断
> - 日志收集和异常告警
> - 灰度发布机制

---

### Q14：如果让你用一句话总结这个项目的技术亮点？

> **"通过Embedding和Rerank的双重微调，配合vLLM高性能部署，实现了88.6%准确率、512并发的RAG问答系统。"**

---

### Q15：这个项目有什么不足或遗憾？

> **没做的部分：**
> - 没有接入真实用户，缺少线上反馈验证
> - 没有实现多轮对话
> - 没有做监控和日志系统
>
> **如果有更多时间会做：**
> - 部署到云服务器，开放API让朋友试用
> - 收集真实反馈，迭代优化
> - 加上前端界面

---

## 总结卡片

```
┌────────────────────────────────────────────┐
│        智能座舱汽车知识问答系统              │
├────────────────────────────────────────────┤
│ 架构：RAG (检索增强生成)                    │
│ 召回：M3E + FAISS + BM25                   │
│ 重排：BGE-reranker-large                   │
│ 生成：Qwen-7B-Chat (vLLM)                  │
│ 部署：4×V100, Docker容器化                  │
├────────────────────────────────────────────┤
│ 核心指标：                                  │
│ • 准确率：88.6% (2000测试样本)              │
│ • 召回：Recall@10 +3%                      │
│ • 重排：Precision +2%                      │
│ • 并发：512 (压测)                         │
│ • 延迟：首Token 2s                         │
├────────────────────────────────────────────┤
│ 性质：学习实践项目，完成离线评测             │
│ 亮点：Embedding微调 + Rerank微调 + vLLM部署 │
└────────────────────────────────────────────┘
```

---

## 面试Tips

1. **诚实为本**：是学习项目就说学习项目，不要编上线经历
2. **强调深度**：虽然没上线，但每个模块都深入理解和实践过
3. **展示潜力**：说清楚"如果上线还需要什么"，体现工程意识
4. **数据说话**：88.6%准确率、512并发，这些是实打实的

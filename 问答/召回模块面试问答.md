# 召回模块面试问答（M3E + FAISS + BM25）

---

## 第一部分：向量召回（M3E + FAISS + 微调）

### 一、Embedding模型基础

#### Q1: 用的是哪个Embedding模型？还对比了哪些模型？

**答：** 我们选用的是 **M3E-large**。

**对比过的模型：**
| 模型 | 维度 | Recall@10 | 中文效果 |
|------|------|-----------|----------|
| text2vec-base-chinese | 768 | 79.2% | ⭐⭐⭐⭐ |
| M3E-base | 768 | 81.5% | ⭐⭐⭐⭐ |
| **M3E-large** | 1024 | **84.3%** | ⭐⭐⭐⭐⭐ |
| BGE-large-zh | 1024 | 83.8% | ⭐⭐⭐⭐⭐ |

**选择M3E-large的原因：**
1. 在汽车领域数据上Recall最高
2. 中文语义理解效果最好（专门为中文优化）
3. 开源免费，可本地部署，数据不出域
4. 1024维向量，表达能力强

---

#### Q2: RAG框架中Retrieve向量召回的基本原理是什么？

**答：** 

**核心流程：**
```
【离线阶段-建索引】
文档chunks → Embedding模型编码 → 1024维向量 → 存入FAISS向量库

【在线阶段-检索】
用户Query → Embedding模型编码 → 1024维向量 → FAISS相似度搜索 → 返回Top-K
```

**为什么有效：**
- Embedding模型通过对比学习训练，学会把语义相似的文本映射到相近的向量
- "机油容量"和"发动机油量"虽然词不同，但向量很接近
- 用向量相似度（余弦/内积）衡量语义相似度

---

#### Q3: Embedding模型是如何部署的？使用了什么工具和框架？

**答：**

```python
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS

# 加载M3E模型
embeddings = HuggingFaceEmbeddings(
    model_name="./pre_train_model/m3e-large",  # model_id: 模型路径
    model_kwargs={"device": "cuda"},            # GPU加速
    encode_kwargs={"batch_size": 64}            # 批量编码
)

# 构建FAISS索引
vector_store = FAISS.from_documents(docs, embeddings)

# 检索
results = vector_store.similarity_search_with_score(query, k=10)
```

**使用的工具：**
| 组件 | 工具 | 作用 |
|------|------|------|
| 模型封装 | LangChain + HuggingFace | 统一接口加载模型 |
| 向量存储 | FAISS | 高效向量检索 |
| 推理加速 | PyTorch CUDA | GPU加速 |

---

#### Q4: Bi-Encoder和Cross-Encoder有什么区别？

**答：** 

| 特性 | Bi-Encoder（M3E用的） | Cross-Encoder（Rerank用的） |
|------|----------------------|---------------------------|
| 输入 | Query和Doc**分别**编码 | Query和Doc**拼接**后一起编码 |
| 输出 | 两个向量，计算相似度 | 直接输出相似度分数 |
| 预计算 | ✅ Doc可离线预计算 | ❌ 必须在线计算 |
| 速度 | **快**（毫秒级） | 慢（百毫秒级） |
| 精度 | 较高 | **更高** |
| 用途 | **召回阶段**（海选） | **重排阶段**（精选） |

---

### 二、向量数据库（FAISS）

#### Q5: FAISS是什么？有哪些索引类型？

**答：** FAISS = Facebook AI Similarity Search

| 索引类型 | 原理 | 精度 | 速度 | 适用规模 |
|----------|------|------|------|----------|
| **Flat** | 暴力遍历 | 100% | 慢 | <10万 |
| **IVF** | 聚类+倒排 | ~95% | 快 | 10万-1000万 |
| **HNSW** | 层级图索引 | ~98% | 很快 | 10万-1亿 |
| **PQ** | 向量压缩 | ~90% | 快 | 亿级 |

**我们用Flat**：数据量不大（几万chunk），保证100%精确召回。

**IVF原理（向量倒排索引）：**
```
1. K-Means聚类，把向量分成n个簇
2. 每个簇有一个中心点
3. 查询时：先找最近的几个簇中心，只在这些簇内搜索
```

**HNSW原理（层级图索引）：**
```
构建多层图结构：
Layer 2:    A -------- B           (稀疏，快速定位)
Layer 1:    A --- C -- B --- D
Layer 0:    A - C - E- B - D - F   (稠密，精确搜索)

查询从高层开始，逐层向下，最终到达目标
```

---

#### Q6: FAISS的IVF和传统倒排索引（BM25）有什么区别？

**答：**

| 对比 | 传统倒排（BM25） | FAISS IVF |
|------|------------------|-----------|
| 索引对象 | **词** | **向量聚类中心** |
| 匹配方式 | 精确词匹配 | 向量相似度 |
| 能处理同义词 | ❌ | ✅ |
| 查询类型 | 关键词搜索 | 语义搜索 |

---

#### Q7: 向量相似度怎么计算？

**答：** 常用三种方法：

| 方法 | 公式 | 值域 | 特点 |
|------|------|------|------|
| **余弦相似度** | (A·B)/(‖A‖×‖B‖) | [-1, 1] | 不考虑长度，只看方向 |
| **内积** | Σ(ai × bi) | 无限 | 向量归一化后=余弦 |
| **欧氏距离** | √Σ(ai-bi)² | [0, ∞) | 值越小越相似 |

**M3E + FAISS用的是内积**（向量已归一化，等价于余弦相似度）。

---

### 三、Embedding微调（重点！）

#### Q8: 为什么要对Embedding模型微调？本质上解决了什么问题？

**答：** 本质是解决**领域适配（Domain Adaptation）**问题。

| 问题 | 原因 | 微调如何解决 |
|------|------|-------------|
| 专业术语理解不准 | M3E没见过"ESP"、"JMEV" | 让模型学习这些词的语义表示 |
| 领域同义词不识别 | 不知道"机油"="发动机油" | 对比学习拉近这些词的向量 |
| 领域语义差异 | "换"在汽车领域通常指"更换保养" | 适应领域特定含义 |

**微调前后的差异：**
```
微调前:
  "机油容量" 和 "机油更换周期" 的向量很近（因为都有"机油"）
  → 容易召回错误答案

微调后:
  "机油容量" 和 "机油容量4.5L" 更近
  "机油容量" 和 "机油更换周期" 被推远
  → 能区分相似但不同的内容
```

---

#### Q9: 评估Embedding模型召回效果的核心指标有哪些？分别代表什么含义？

**答：** 两个核心指标：**Hit Rate（命中率）** 和 **MRR（平均倒数排名）**

**1. Hit Rate@K（也叫Recall@K）：**
```
定义：Top-K召回结果中，命中正确答案的query占比

公式：Hit Rate@K = 命中的query数 / 总query数

例子：
- 100个测试问题
- 其中85个问题的正确答案出现在了Top-10召回结果中
- Hit Rate@10 = 85%
```

**2. MRR（Mean Reciprocal Rank）：**
```
定义：正确答案排名的倒数的平均值

公式：MRR = (1/N) × Σ(1/rank_i)

例子：
- Query1的正确答案排第1位: 1/1 = 1.0
- Query2的正确答案排第3位: 1/3 = 0.33
- Query3的正确答案排第2位: 1/2 = 0.5
- MRR = (1.0 + 0.33 + 0.5) / 3 = 0.61
```

**两者区别：**
| 指标 | 关注点 | 特点 |
|------|--------|------|
| Hit Rate@K | 有没有召回 | 只看是否在Top-K内，不管排第几 |
| MRR | 排在第几 | 排名越靠前分数越高 |

---

#### Q10: 评估数据集和微调训练数据集分别是什么领域的数据？为什么选择该领域？

**答：**

**数据领域：汽车用户手册问答**

| 数据集 | 数量 | 用途 |
|--------|------|------|
| 训练集 | 1600条Q&A → 约4800条三元组 | 微调模型 |
| 验证集 | 200条Q&A | 监控训练 |
| 测试集 | 400条Q&A | 评估效果 |

**为什么选择汽车领域：**
1. **业务需求**：项目就是做汽车车主问答系统
2. **领域特殊性**：汽车有很多专业术语（ESP、JMEV、变速箱油）
3. **通用模型不够**：M3E是通用模型，不了解汽车领域语义

---

#### Q11: 微调前的数据集准备包括哪些步骤？如何生成QA嵌入对？

**答：** 

**Step 1：原始数据**
```
我们有2000条人工标注的(Question, Answer)对
例如：
{
  "question": "机油容量是多少",
  "answer": "4.5L"
}
```

**Step 2：划分数据集**
```
总数据 2000条（人工标注用于Embedding微调）
├── 训练集: 1400条 (70%)
├── 验证集: 200条 (10%)
└── 测试集: 400条 (20%)

注：端到端系统评估使用完整2000条测试集
```

**Step 3：构造训练三元组**

这是关键步骤！需要构造 **(Query, Positive, Negative)** 三元组：

```python
def prepare_training_data(labeled_data, all_chunks, retriever):
    """
    labeled_data: 标注的Q&A对
    all_chunks: 所有文档块
    retriever: 当前的检索器（用于Hard Negative Mining）
    """
    triplets = []
    
    for item in labeled_data:
        query = item['question']   # "机油容量是多少"
        answer = item['answer']    # "4.5L"
        
        # === 1. 找Positive：包含答案的chunk ===
        positive = None
        for chunk in all_chunks:
            if answer in chunk:  # 答案出现在这个chunk里
                positive = chunk  # "发动机机油容量为4.5L（含滤清器）..."
                break
        
        if positive is None:
            continue  # 找不到就跳过
        
        # === 2. Hard Negative Mining ===
        # 用当前模型召回Top-20
        candidates = retriever.search(query, top_k=20)
        
        # 去掉正确答案，剩下的是"很像但不对"的Hard Negative
        hard_negatives = []
        for candidate in candidates:
            if candidate != positive and answer not in candidate:
                hard_negatives.append(candidate)
        
        # === 3. 构造三元组 ===
        # 每个query配3个负样本，增加数据量
        for neg in hard_negatives[:3]:
            triplets.append({
                'query': query,
                'positive': positive,
                'negative': neg
            })
    
    return triplets

# 最终得到约 1600 × 3 ≈ 4800条训练数据
```

**数据示例：**
```python
{
    'query': '机油容量是多少',
    'positive': '发动机机油容量为4.5L（含机油滤清器），建议使用5W-30规格机油',
    'negative': '机油更换周期为每10000公里或12个月，以先到者为准'  # Hard Negative！
}
```

**为什么要Hard Negative：**
```
❌ Random Negative: "今天天气真好"
   → 和query完全不相关，模型轻松区分，学不到东西

✅ Hard Negative: "机油更换周期是多久"  
   → 词汇很像（都有"机油"），但答案不对
   → 迫使模型学习更细粒度的语义差异
```

---

#### Q12: 微调过程中，模型的输入输出是什么？

**答：**

**输入：三元组 (Query, Positive, Negative)**
```python
# 一个训练样本
InputExample(texts=[
    "机油容量是多少",            # Query (anchor)
    "机油容量为4.5L含滤清器",    # Positive
    "机油更换周期10000公里"      # Negative
])
```

**模型处理过程：**
```python
# 模型分别对三个文本编码，得到三个向量
query_vec = model.encode("机油容量是多少")         # [1024维向量]
pos_vec   = model.encode("机油容量为4.5L...")     # [1024维向量]
neg_vec   = model.encode("机油更换周期...")       # [1024维向量]
```

**输出：计算TripletLoss，更新模型参数**

---

#### Q13: 损失函数TripletLoss是什么？怎么理解？

**答：** TripletLoss的目标是让**Query和Positive靠近，Query和Negative远离**。

**公式：**
```python
loss = max(0, margin + dist(query, positive) - dist(query, negative))

# dist() 是距离函数，可以是：
# - 1 - cosine_similarity  (我们用的)
# - 欧氏距离
```

**直观理解：**
```
假设 margin = 0.2

情况1: dist(Q,P)=0.3, dist(Q,N)=0.8
  loss = max(0, 0.2 + 0.3 - 0.8) = max(0, -0.3) = 0  ✅ 不需要优化

情况2: dist(Q,P)=0.5, dist(Q,N)=0.6  
  loss = max(0, 0.2 + 0.5 - 0.6) = max(0, 0.1) = 0.1  ❌ 需要优化

情况3: dist(Q,P)=0.6, dist(Q,N)=0.4  (负样本比正样本还近！)
  loss = max(0, 0.2 + 0.6 - 0.4) = max(0, 0.4) = 0.4  ❌❌ 严重问题
```

**训练目标：**
```
希望达到: dist(Q, Positive) + margin < dist(Q, Negative)

也就是说：
- Query和Positive的距离要小
- Query和Negative的距离要大
- 两者差距至少要有margin（0.2）
```

**为什么这样设计：**
- 不只是要求P比N近，而是要求**近出一个margin**
- 这样学出来的向量空间更有区分度
- margin太小学不好，太大难收敛，0.2是经验值

---

#### Q14: 微调训练数据集的样本量是多少？样本量对微调效果有影响吗？

**答：**

**我们的样本量：**
- 原始标注：1600条Q&A
- 构造三元组后：约4800条（每个Q配3个负样本）

**样本量的影响：**
| 样本量 | 效果 | 风险 |
|--------|------|------|
| <1000 | 提升有限 | **过拟合**，泛化差 |
| 3000-10000 | 效果好 | 平衡点 |
| >50000 | 边际效益递减 | 训练成本高 |

**如果样本量不足会出现的问题：**
1. **过拟合**：训练集效果好，测试集差
2. **泛化能力弱**：只能处理见过类型的问题
3. **训练不稳定**：loss震荡

**解决方案：**
```python
# 1. 增加负样本数量（每个query配更多hard negative）
for neg in hard_negatives[:5]:  # 从3个改成5个
    triplets.append(...)

# 2. 数据增强
def augment(query):
    # 同义词替换、随机删词、回译等
    pass

# 3. 用预训练模型（而不是从头训练）
model = SentenceTransformer('m3e-large')  # 已经学了很多知识
```

---

#### Q15: 微调过程中是否设置了验证集？

**答：** 是的，用于监控训练过程，防止过拟合。

**数据划分：**
```
总数据 2000条
├── 训练集: 1400条 (70%)
├── 验证集: 200条 (10%)  ← 监控用
└── 测试集: 400条 (20%)
```

**验证集的作用：**
```python
from sentence_transformers import evaluation

# 定义验证器
evaluator = evaluation.InformationRetrievalEvaluator(
    queries=val_queries,
    corpus=all_chunks,
    relevant_docs=val_relevants
)

# 训练时每500步评估一次
model.fit(
    train_objectives=[(dataloader, loss)],
    evaluator=evaluator,
    evaluation_steps=500,  # 每500步在验证集上评估
    ...
)
```

**监控的指标：**
- 如果训练集loss下降，但验证集指标不涨甚至下降 → 过拟合
- 此时应该Early Stopping

---

#### Q16: 请简述Embedding模型微调的完整流程（从数据准备到模型保存）

**答：**

```python
from sentence_transformers import SentenceTransformer, InputExample, losses
from torch.utils.data import DataLoader

# ===== Step 1: 加载预训练模型 =====
model = SentenceTransformer('moka-ai/m3e-large')
# model_id: 预训练模型的标识/路径

# ===== Step 2: 准备训练数据（三元组） =====
train_examples = [
    InputExample(texts=[t['query'], t['positive'], t['negative']])
    for t in training_triplets  # 约4800条
]
train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)

# ===== Step 3: 定义损失函数 =====
train_loss = losses.TripletLoss(
    model=model,
    distance_metric=losses.TripletDistanceMetric.COSINE,
    triplet_margin=0.2
)

# ===== Step 4: 训练 =====
model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=3,
    warmup_steps=100,
    evaluation_steps=500,
    evaluator=evaluator,  # 验证集评估器
    output_path='./m3e-finetuned'  # model_output_path: 保存路径
)

# ===== Step 5: 加载和使用 =====
model = SentenceTransformer('./m3e-finetuned')
```

**训练参数：**
| 参数 | 值 | 说明 |
|------|-----|------|
| batch_size | 16 | 受显存限制 |
| epochs | 3 | 防止过拟合 |
| learning_rate | 2e-5 | 默认值 |
| triplet_margin | 0.2 | 正负样本最小间隔 |
| warmup_steps | 100 | 学习率预热 |

---

#### Q17: top_1到top_5召回的指标变化趋势是什么？

**答：**

| K值 | Hit Rate（微调前） | Hit Rate（微调后） | 提升 |
|-----|-------------------|-------------------|------|
| top_1 | 52.3% | 58.1% | **+5.8%** |
| top_3 | 71.5% | 76.2% | +4.7% |
| top_5 | 78.2% | 82.5% | +4.3% |
| top_10 | 84.3% | 87.2% | +2.9% |

**趋势分析：**
- **K越小，提升越明显**：top_1提升5.8%，top_10只提升2.9%
- 原因：对比学习让正确答案排得更靠前（从第5名变第1名）
- **核心提升点在top_1 ~ top_3**

---

#### Q18: MRR指标的提升幅度与Hit Rate是否一致？

**答：** **不完全一致，MRR的相对提升更大。**

| 指标 | 微调前 | 微调后 | 绝对提升 | 相对提升 |
|------|--------|--------|----------|----------|
| Hit Rate@10 | 84.3% | 87.2% | +2.9% | +3.4% |
| MRR | 0.62 | 0.68 | +0.06 | **+9.7%** |

**原因：**
- Hit Rate只看"有没有在Top-K内"
- MRR关注"排第几"
- 很多query的正确答案从第5位提升到第2位
  - Hit Rate@10不变（都在Top10内）
  - 但MRR提升了（1/5=0.2 → 1/2=0.5）

---

#### Q19: 微调过程中可能遇到的问题有哪些？如何解决？

**答：**

| 问题 | 表现 | 原因 | 解决方案 |
|------|------|------|----------|
| **训练不收敛** | loss不下降或震荡 | 学习率太大/数据质量差 | 降低lr到1e-5，检查数据 |
| **过拟合** | 训练集好，验证集差 | 数据量不足/epoch太多 | Early Stopping、数据增强 |
| **提升不明显** | 指标只提升1% | 负样本太简单 | 改用Hard Negative Mining |
| **显存不足** | OOM错误 | batch_size太大 | 减小batch，用梯度累积 |

**我们遇到的具体问题：**
```
问题1: 第一次训练只提升1%
原因: 负样本是随机采样的，太简单
解决: 改用Hard Negative Mining → 最终Recall@10提升约3%

问题2: 第3个epoch验证集指标开始下降
原因: 过拟合
解决: Early Stopping，实际跑2.5个epoch
```

---

#### Q20: 如果要将微调后的模型应用到其他领域（如医疗、金融），需要做哪些适配调整？

**答：**

| 步骤 | 说明 |
|------|------|
| 1. 收集领域数据 | 医疗问答、金融FAQ等Q&A对 |
| 2. 标注或构造 | 至少1000条以上 |
| 3. 重新构造三元组 | 用新领域数据做Hard Negative Mining |
| 4. 重新微调 | 可以从M3E或我们微调的模型继续 |
| 5. 领域词典 | 医疗术语、金融术语的分词优化 |

**迁移策略：**
```python
# 方案1: 从原始M3E开始微调（推荐，领域差异大时）
model = SentenceTransformer('moka-ai/m3e-large')

# 方案2: 从我们的模型继续微调（领域相近时）
model = SentenceTransformer('./m3e-car-finetuned')
```

---

#### Q21: 除了微调Embedding模型，RAG框架中还有哪些提升Retrieve阶段召回效果的方法？

**答：**

| 方法 | 说明 | 效果 |
|------|------|------|
| **多路召回** | BM25 + 向量混合 | Recall +7% |
| **Embedding微调** | 对比学习 | Recall +3% |
| **Query改写** | 同义词扩展、HyDE | Recall +2% |
| **优化分块** | 语义分块、父子文档 | 提升chunk质量 |
| **领域词典** | 专业术语分词 | 提升BM25 |
| **Rerank重排** | Cross-Encoder | Precision +2% |

---

## 第二部分：稀疏召回（BM25）

### 一、BM25原理

#### Q22: BM25是什么？原理是什么？

**答：** BM25 = Best Matching 25，基于词频统计的检索算法。

**核心公式：**
```
score = Σ IDF(词) × TF(词) × (k1+1) / (TF + k1×(1-b+b×文档长度/平均长度))
```

**三个核心因素：**
| 因素 | 作用 |
|------|------|
| **TF（词频）** | 词出现越多越相关，但有饱和度 |
| **IDF（逆文档频率）** | 稀有词权重更高（"机油"比"的"重要） |
| **长度归一化** | 长文档不因词多就占优 |

**参数：**
- k1（默认1.5）：控制词频饱和度
- b（默认0.75）：控制长度归一化强度

---

#### Q23: BM25和TF-IDF有什么区别？

**答：**

| 对比 | TF-IDF | BM25 |
|------|--------|------|
| TF处理 | 线性增长 | 有饱和度（k1控制） |
| 长度归一化 | 无 | 有（b参数控制） |
| 效果 | 一般 | 更好 |

**BM25改进点：** 词出现10次 vs 5次，TF-IDF分数差2倍，BM25差距更小（饱和效应）。

---

#### Q24: BM25的倒排索引怎么工作？

**答：**

**结构：词 → 文档列表**
```
"机油" → [doc1, doc2, doc5]
"容量" → [doc1, doc8]
```

**查询过程：**
```
Query: "机油容量"
分词:  ["机油", "容量"]
查倒排: "机油"→[doc1,doc2,doc5], "容量"→[doc1,doc8]
候选: doc1, doc2, doc5, doc8
BM25打分: doc1最高（两词都匹配）
```

---

### 二、BM25优化

#### Q25: BM25需要微调吗？怎么优化？

**答：** BM25不是神经网络，没有"微调"，但可以优化：

**1. 加载领域词典（最重要！）：**
```python
jieba.load_userdict("car_terms.txt")
# car_terms.txt:
# 机油滤清器 5 n
# 变速箱油 5 n
# ESP 5 n
# JMEV 5 n
```

**2. 停用词过滤：**
```python
stopwords = {'的', '是', '在', '了', '和', '与', '或'}
tokens = [t for t in jieba.cut(text) if t not in stopwords]
```

**3. 同义词扩展：**
```python
synonyms = {
    '机油': ['发动机油', '润滑油'],
    '换': ['更换', '替换'],
}
```

**4. 调整超参数：** k1、b根据文档长度分布调整。

---

#### Q26: 为什么用jieba.cut_for_search？

**答：** jieba有三种模式：

| 模式 | 效果 |
|------|------|
| 精确模式 | "发动机机油" → ["发动机", "机油"] |
| 全模式 | "发动机机油" → ["发动", "动机", "发动机", "机", "机油", "油"] |
| **搜索引擎模式** | "发动机机油" → ["发动", "动机", "发动机", "机油"] |

**搜索引擎模式的好处：** 既有长词又有短词，查询"发动"也能匹配"发动机机油"。

---

## 第三部分：多路召回融合 + Query改写

### 一、多路召回融合

#### Q27: 为什么要BM25和向量检索一起用？

**答：** **互补！**

| 场景 | BM25 | 向量检索 | 原因 |
|------|------|----------|------|
| "JMEV-01手册" | ✅ | ❌ | BM25精确匹配专有名词 |
| "发动机油量多少" | ❌ | ✅ | 向量理解"发动机油"="机油" |
| 稀有词查询 | ✅ | ❌ | BM25的IDF给稀有词高权重 |
| 同义词匹配 | ❌ | ✅ | 向量捕捉语义相似 |

**融合效果：**
| 方式 | Recall@10 |
|------|-----------|
| 只用BM25 | 76% |
| 只用向量 | 87% |
| **BM25 + 向量** | **91%** |

---

#### Q28: 多路召回结果怎么合并？

**答：** 几种策略：

**1. 简单合并去重（我们用的）：**
```python
def merge_results(bm25_results, vector_results):
    seen = set()
    merged = []
    for doc in bm25_results + vector_results:
        if doc.page_content not in seen:
            seen.add(doc.page_content)
            merged.append(doc)
    return merged
```

**2. RRF（Reciprocal Rank Fusion）：**
```python
def rrf_merge(results_list, k=60):
    scores = {}
    for results in results_list:
        for rank, doc in enumerate(results):
            if doc not in scores:
                scores[doc] = 0
            scores[doc] += 1 / (k + rank + 1)
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)
```

**3. 加权融合：**
```python
final_score = 0.3 * bm25_score + 0.7 * vector_score
```

---

### 二、Query改写优化

#### Q29: 有做Query改写吗？怎么做的？

**答：** 是的，我们做了两种Query改写来提升召回：

**1. 同义词扩展：**
```python
def expand_query(query):
    tokens = list(jieba.cut(query))
    expanded = tokens.copy()
    
    synonyms = {
        '机油': ['发动机油', '润滑油'],
        '换': ['更换', '替换'],
        '多少': ['是多少', '容量'],
    }
    
    for token in tokens:
        if token in synonyms:
            expanded.extend(synonyms[token])
    
    return " ".join(expanded)

# "机油容量" → "机油 发动机油 润滑油 容量"
```

**2. HyDE（Hypothetical Document Embedding）：**
```python
def hyde_rewrite(query, llm):
    """用LLM生成假设性答案，用答案去检索"""
    prompt = f"请回答这个问题（即使你不确定也请给出可能的答案）：{query}"
    hypothetical_answer = llm.generate(prompt)
    
    # 用假设答案去检索，效果更好
    return hypothetical_answer

# Query: "机油容量是多少"
# HyDE: "这款车的机油容量是4.5升，建议使用5W-30规格的机油"
# 用HyDE结果去检索，能召回更相关的文档
```

**效果：**
| 方法 | Recall@10提升 |
|------|---------------|
| 同义词扩展 | +1.5% |
| HyDE | +2.3% |

---

## 第四部分：召回方法总览与选型

#### Q30: RAG中有哪些常见的召回方法？

**答：**

| 方法 | 原理 | 优点 | 缺点 |
|------|------|------|------|
| **稀疏检索（BM25）** | 词频统计+倒排索引 | 精确匹配、速度快 | 不理解语义 |
| **稠密检索（向量）** | Embedding+ANN | 语义理解、同义词 | 专有名词差 |
| **混合检索** | BM25+向量 | 互补、效果最好 | 需要融合策略 |
| **知识图谱** | 实体关系图 | 结构化推理 | 构建成本高 |

---

#### Q31: 你们的召回方案是怎么设计的？

**答：**

| 方法 | 是否使用 | 效果 |
|------|----------|------|
| 向量检索（M3E） | ✅ | 基础召回 |
| 稀疏检索（BM25） | ✅ | 补充精确匹配 |
| Embedding微调 | ✅ | +3%召回 |
| Query改写 | ✅ | +2%召回 |
| Rerank重排 | ✅ | Precision +2%（下一模块讲） |

**最终方案：**
```
BM25召回Top15 + 向量召回Top15 → 合并去重 → Rerank重排 → Top6给LLM
```

---

## 总结

召回模块面试重点：

1. **Embedding模型**：为什么选M3E，Bi-Encoder vs Cross-Encoder
2. **FAISS向量库**：索引类型（Flat/IVF/HNSW），原理区别
3. **微调（重点！）**：
   - 数据构造：三元组 + Hard Negative Mining
   - 损失函数：TripletLoss的原理和margin含义
   - 评估指标：Hit Rate@K 和 MRR
   - 效果：+3% Recall，核心提升在top_1~top_3
4. **BM25**：原理、倒排索引、优化方法
5. **多路融合**：为什么互补，怎么合并
6. **Query改写**：同义词扩展、HyDE

建议面试时结合具体数据和效果来回答，展示对细节的掌握。
